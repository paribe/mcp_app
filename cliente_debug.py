import asyncio
import json
from typing import Any, Dict
import aiohttp
import os
from dotenv import load_dotenv
from openai import OpenAI

import asyncio
import json
from typing import Any, Dict
import aiohttp
import os
from dotenv import load_dotenv
from openai import OpenAI

# Carrega vari√°veis de ambiente de forma mais robusta
def carregar_env():
    # Tenta carregar do diret√≥rio atual
    if os.path.exists('.env'):
        load_dotenv('.env')
        print("‚úÖ Arquivo .env carregado do diret√≥rio atual")
    elif os.path.exists('/home/paribe/mcp_app/.env'):
        load_dotenv('/home/paribe/mcp_app/.env')
        print("‚úÖ Arquivo .env carregado do caminho completo")
    else:
        print("‚ö†Ô∏è Arquivo .env n√£o encontrado")
    
    # Verifica se a chave foi carregada
    api_key = os.getenv('OPENAI_API_KEY')
    if api_key:
        print(f"üîë Chave OpenAI carregada: {api_key[:10]}...")
    else:
        print("‚ùå Chave OpenAI n√£o encontrada nas vari√°veis de ambiente")
    
    return api_key

# Carrega as vari√°veis de ambiente
API_KEY = carregar_env()

class ClienteMCP:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = None
        print(f"üåê Cliente inicializado com URL: {self.base_url}")
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        print("üîó Sess√£o aiohttp criada")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
            print("üîå Sess√£o aiohttp fechada")
    
    async def chamar_ferramenta(self, nome_ferramenta: str, argumentos: Dict[str, Any]) -> str:
        """Chama uma ferramenta no servidor MCP"""
        if not self.session:
            raise RuntimeError("Cliente n√£o inicializado. Use async with.")
        
        url = f"{self.base_url}/tools/{nome_ferramenta}"
        print(f"üì° Fazendo requisi√ß√£o para: {url}")
        print(f"üì¶ Com dados: {argumentos}")
        
        try:
            headers = {'Content-Type': 'application/json'}
            async with self.session.post(url, json=argumentos, headers=headers) as response:
                print(f"üìä Status da resposta: {response.status}")
                
                if response.status == 200:
                    resultado = await response.json()
                    print(f"‚úÖ Resposta recebida: {str(resultado)[:100]}...")
                    return resultado.get('content', '')
                else:
                    texto_resposta = await response.text()
                    print(f"‚ùå Erro na resposta: {texto_resposta}")
                    return f"Erro na requisi√ß√£o: {response.status} - {texto_resposta}"
        except Exception as e:
            print(f"‚ùå Erro na conex√£o: {str(e)}")
            return f"Erro ao conectar com o servidor: {str(e)}"

# Inst√¢ncia global do cliente
cliente_mcp = ClienteMCP()

async def testar_servidor(cliente: ClienteMCP, busca: str) -> str:
    """Testa o servidor buscando informa√ß√µes e gerando resposta com IA"""
    print(f"üöÄ Iniciando teste com busca: {busca}")
    
    async with cliente:
        # Busca informa√ß√µes na Wikipedia via servidor MCP
        resultado_busca = await cliente.chamar_ferramenta(
            "buscar_wikipedia", 
            {"busca": busca}
        )
        
        print(f"üìã Resultado da busca: {resultado_busca[:100]}...")
        
        # Se houve erro na busca, retorna o erro
        if resultado_busca.startswith("Erro"):
            return resultado_busca
        
        # Usa OpenAI para gerar uma resposta mais elaborada
        try:
            # Usa a chave carregada globalmente
            if not API_KEY:
                print("‚ö†Ô∏è Chave OpenAI n√£o dispon√≠vel, retornando s√≥ Wikipedia")
                return f"**Informa√ß√µes da Wikipedia:**\n\n{resultado_busca}"
            
            print("ü§ñ Gerando resposta com OpenAI...")
            client = OpenAI(api_key=API_KEY)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um assistente √∫til que explica conceitos de forma clara e did√°tica em portugu√™s."
                    },
                    {
                        "role": "user",
                        "content": f"Com base nas informa√ß√µes da Wikipedia abaixo sobre '{busca}', forne√ßa um resumo claro e informativo:\n\n{resultado_busca}"
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro com OpenAI: {str(e)}")
            # Se falhar com OpenAI, retorna apenas o resultado da Wikipedia
            return f"**Informa√ß√µes da Wikipedia:**\n\n{resultado_busca}\n\n*Nota: N√£o foi poss√≠vel gerar resumo com IA: {str(e)}*"

if __name__ == "__main__":
    # Teste b√°sico
    async def teste():
        resultado = await testar_servidor(cliente_mcp, "Python")
        print("üéØ RESULTADO FINAL:")
        print(resultado)
    
    asyncio.run(teste())